{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3265ea5b",
   "metadata": {},
   "source": [
    "This code is based on https://www.youtube.com/watch?v=0Ag83EhYD7k&t=1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "bc85cb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "eb9c153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelMix(nn.Module):\n",
    "    def __init__(self, layer_id, n_layer, n_embed):\n",
    "        super().__init__()\n",
    "        self.layer_id = layer_id\n",
    "        \n",
    "        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1)) # How does this work to induce time shift?\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ratio_1_to_almost0 = 1.0 - layer_id/n_layer # What does this ratio do?\n",
    "            x = torch.ones(1,1,n_embed)\n",
    "            for i in range(n_embed):\n",
    "                x[0, 0, i] = i/n_embed\n",
    "            \n",
    "            self.time_mix_k = nn.Parameter(torch.pow(x, ratio_1_to_almost0)) # This initializes the trainable value mu_k (eq 17)\n",
    "            self.time_mix_r = nn.Parameter(torch.pow(x, ratio_1_to_almost0)) # This initializes the trainable value mu_r (eq 16)\n",
    "            \n",
    "        hidden_size = 4*n_embed\n",
    "        self.key = nn.Linear(n_embed, hidden_size, bias=False) # This function left-multiplies by W_k (eq 17)\n",
    "        self.receptance = nn.Linear(n_embed, n_embed, bias=False) # This function left-multiplies by W_r (eq 16)\n",
    "        \n",
    "        self.value = nn.Linear(hidden_size, n_embed, bias=False) # This function left-multiplies by W_v (eq 18)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        xx = self.time_shift(x)\n",
    "        xr = x * self.time_mix_r + (1-self.time_mix_r) * xx # eq 16\n",
    "        xk = x * self.time_mix_k + (1-self.time_mix_k) * xx # eq 17\n",
    "        \n",
    "        k = self.key(xk) # eq 17 cont.\n",
    "        r = self.receptance(xr) # eq 16 cont.\n",
    "        \n",
    "        k = torch.square(torch.relu(k)) # eq 18\n",
    "        rkv = torch.sigmoid(r) * self.value(k) # eq 18 cont.\n",
    "        \n",
    "        return rkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "315f111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeMix(nn.Module):\n",
    "    def __init__(self, layer_id, n_layer, n_embed):\n",
    "        super().__init__()\n",
    "        self.layer_id = layer_id\n",
    "        \n",
    "        attn_sz = n_embed\n",
    "        with torch.no_grad():\n",
    "            ratio_1_to_almost0 = 1.0 - layer_id/n_layer\n",
    "            ratio_0_to_1 = layer_id / (n_layer - 1)\n",
    "            \n",
    "            decay_speed = torch.ones(attn_sz)\n",
    "            for h in range(attn_sz):\n",
    "                decay_speed[h] = -5 + 8 * (h / (attn_sz-1)) ** (0.7 + 1.3 * ratio_0_to_1)\n",
    "                \n",
    "            self.time_decay = nn.Parameter(decay_speed)\n",
    "            \n",
    "            zigzag = (torch.tensor([(i+1)%3 - 1 for i in range(attn_sz)]) * 0.5)\n",
    "            # In the paper, this variable is u... what does it do?\n",
    "            self.time_first = nn.Parameter(torch.ones(attn_sz) * math.log(0.3) + zigzag)\n",
    "            \n",
    "            x = torch.ones(1,1, n_embed)\n",
    "            for i in range(n_embed):\n",
    "                x[0,0,i] = i/n_embed\n",
    "            \n",
    "            self.time_mix_k = nn.Parameter(torch.pow(x, ratio_1_to_almost0)) # This initializes the trainable value mu_k (eq 12)\n",
    "            self.time_mix_v = nn.Parameter(torch.pow(x, ratio_1_to_almost0)) # This initializes the trainable value mu_v (eq 13)\n",
    "            self.time_mix_r = nn.Parameter(torch.pow(x, ratio_1_to_almost0)) # This initializes the trainable value mu_r (eq 11)\n",
    "            \n",
    "            # aa, bb, pp, xx are all involved in the RNN formulation of time-mixing (see Appendix B)\n",
    "            self.aa = nn.Parameter(torch.ones(1,1,attn_sz))\n",
    "            self.bb = nn.Parameter(torch.ones(1,1,attn_sz))\n",
    "            pp = torch.ones(1,1,attn_sz)\n",
    "            pp = pp * -1e30\n",
    "            self.pp = nn.Parameter(pp)\n",
    "            self.xx = nn.Parameter(torch.ones(1,1,attn_sz))\n",
    "            \n",
    "        hidden_size = attn_sz\n",
    "        self.key = nn.Linear(n_embed, attn_sz, bias=False)  # This function left-multiplies by W_k (eq 12)\n",
    "        self.receptance = nn.Linear(n_embed, attn_sz, bias=False)  # This function left-multiplies by W_r (eq 11)\n",
    "        \n",
    "        self.value = nn.Linear(hidden_size, attn_sz, bias=False)  # This function left-multiplies by W_v (eq 13)\n",
    "        self.output = nn.Linear(attn_sz, n_embed, bias=False)  # This function left-multiplies by W_o (eq 15)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        xx = self.xx\n",
    "        \n",
    "        xk = x * self.time_mix_k + (1-self.time_mix_k) * xx\n",
    "        xv = x * self.time_mix_v + (1-self.time_mix_v) * xx\n",
    "        xr = x * self.time_mix_r + (1-self.time_mix_r) * xx\n",
    "        \n",
    "        k = self.key(xk)\n",
    "        v = self.value(xv)\n",
    "        r = self.receptance(xr)\n",
    "        \n",
    "        r = torch.sigmoid(r)\n",
    "        \n",
    "        # Calculate the difference in size along the non-singleton dimension\n",
    "        diff = k.shape[1] - self.aa.shape[1]\n",
    "        \n",
    "        b,t,c = x.shape\n",
    "        aa = torch.nn.functional.pad(self.aa, (0,0,0,diff,0,0))\n",
    "        bb = torch.nn.functional.pad(self.bb, (0,0,0,diff,0,0))\n",
    "        pp = torch.nn.functional.pad(self.pp, (0,0,0,diff,0,0))\n",
    "        \n",
    "        ww = self.time_first + k # eq 25 (u + k_t)\n",
    "        \n",
    "        qq = torch.maximum(pp, ww) # eq 25\n",
    "        e1 = torch.exp(pp - qq)\n",
    "        e2 = torch.exp(ww - qq)\n",
    "        \n",
    "        a = e1 * aa + e2 * v # eq 26 \n",
    "        b = e1 * bb + e2 # eq 27\n",
    "        wkv = a / b # eq 28\n",
    "        \n",
    "        ww = pp + self.time_decay # eq 29... why + not -?\n",
    "        qq = torch.maximum(ww, k) # eq 29\n",
    "        e1 = torch.exp(ww - qq)\n",
    "        e2 = torch.exp(k - qq)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            xx = nn.Parameter(x) # should this be 'self.xx = ...'?\n",
    "            self.aa = nn.Parameter(e1 * aa + e2 * v) # eq 30\n",
    "            self.bb = nn.Parameter(e1 * bb + e2) # eq 31\n",
    "            self.pp = nn.Parameter(qq) # eq 32\n",
    "            \n",
    "        return self.output(r * wkv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4dade446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, layer_id, n_layer, n_embed):\n",
    "        super().__init__()\n",
    "        self.layer_id = layer_id\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "        \n",
    "        if self.layer_id == 0:\n",
    "            self.ln0 = nn.LayerNorm(n_embed)\n",
    "        \n",
    "        if self.layer_id == 0:\n",
    "            self.ffnPre = ChannelMix(0, n_layer, n_embed)\n",
    "        else:\n",
    "            self.att = TimeMix(layer_id, n_layer, n_embed)\n",
    "        \n",
    "        self.ffn = ChannelMix(layer_id, n_layer, n_embed)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.layer_id == 0:\n",
    "            x = self.ln0(x)\n",
    "        if self.layer_id == 0:\n",
    "            x = x + self.ffnPre(self.ln1(x))\n",
    "        else:\n",
    "            x = x + self.att(self.ln1(x))\n",
    "        x = x + self.ffn(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "dec972d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RWKV(nn.Module):\n",
    "    def __init__(self, n_layer, vocab_size, n_embed, ctx_len):\n",
    "        super().__init__()\n",
    "        self.step = 0\n",
    "        self.ctx_len = ctx_len\n",
    "        self.emb = nn.Embedding(vocab_size, n_embed)\n",
    "        \n",
    "        self.blocks = nn.Sequential(*[Block(i, n_layer, n_embed)\n",
    "                                     for i in range(n_layer)])\n",
    "        self.ln_out = nn.LayerNorm(n_embed)\n",
    "        # head is the output layer that redimensions to the vocab size to predict an output word\n",
    "        self.head = nn.Linear(n_embed, vocab_size, bias=False)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        idx = idx.to(self.emb.weight.device)\n",
    "        \n",
    "        self.step += 1\n",
    "        \n",
    "        B, T = idx.size()\n",
    "        assert T <= self.ctx_len, \"Cannot forward, because len(input) > model ctx_len.\"\n",
    "        \n",
    "        x = self.emb(idx)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_out(x)\n",
    "        \n",
    "        x = self.head(x)\n",
    "        \n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(x.view(-1, x.size(-1)), targets.to(x.device).view(-1))\n",
    "        x = torch.mean(x, dim=0, keepdim=True)\n",
    "        return x,loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokes):\n",
    "        for _ in range(max_new_tokes):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b72a407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences are processed in parallel\n",
    "block_size = 32 # what is the maximum context length for predictions? # Does this make sense for RWKV???\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embed = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# --------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0a8f0",
   "metadata": {},
   "source": [
    "Testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a9aab383",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "81b163cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "01840040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "90fd927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "819d08b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(''.join(chars)) # print the vocabulary\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e9f60520",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8c118510",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s : [stoi[c] for c in s]\n",
    "decode = lambda l : \"\".join([itos[x] for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "87e61ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61, 46, 39, 58, 5, 57, 1, 59, 54, 2]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"what's up!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a07b4d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"what's up!\""
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([61, 46, 39, 58, 5, 57, 1, 59, 54, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7f886ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "6c8702da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "9e62da6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1115394]), torch.Tensor)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "447052bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "766a3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "3d9f1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3814408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[1:block_size+1] # sliding window for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "58611c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18, 47, 56, 57, 58,  1, 15, 47]),\n",
       " tensor([47, 56, 57, 58,  1, 15, 47, 58]))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9ffdda4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctx  tensor([18]) target tensor(47)\n",
      "ctx  tensor([18, 47]) target tensor(56)\n",
      "ctx  tensor([18, 47, 56]) target tensor(57)\n",
      "ctx  tensor([18, 47, 56, 57]) target tensor(58)\n",
      "ctx  tensor([18, 47, 56, 57, 58]) target tensor(1)\n",
      "ctx  tensor([18, 47, 56, 57, 58,  1]) target tensor(15)\n",
      "ctx  tensor([18, 47, 56, 57, 58,  1, 15]) target tensor(47)\n",
      "ctx  tensor([18, 47, 56, 57, 58,  1, 15, 47]) target tensor(58)\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(\"ctx \", context, \"target\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ef5f7746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28a5a7f46b0>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "5485dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "410c49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a batch of input data x and targets y\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix]) # Train on every subsequence within the input sequence\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "bbaabe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b66a556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xb)\n",
    "xb.shape == yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f1265de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24]) ----- tensor(43)\n",
      "tensor([24, 43]) ----- tensor(58)\n",
      "tensor([24, 43, 58]) ----- tensor(5)\n",
      "tensor([24, 43, 58,  5]) ----- tensor(57)\n",
      "tensor([24, 43, 58,  5, 57]) ----- tensor(1)\n",
      "tensor([24, 43, 58,  5, 57,  1]) ----- tensor(46)\n",
      "tensor([24, 43, 58,  5, 57,  1, 46]) ----- tensor(43)\n",
      "tensor([24, 43, 58,  5, 57,  1, 46, 43]) ----- tensor(39)\n",
      "tensor([44]) ----- tensor(53)\n",
      "tensor([44, 53]) ----- tensor(56)\n",
      "tensor([44, 53, 56]) ----- tensor(1)\n",
      "tensor([44, 53, 56,  1]) ----- tensor(58)\n",
      "tensor([44, 53, 56,  1, 58]) ----- tensor(46)\n",
      "tensor([44, 53, 56,  1, 58, 46]) ----- tensor(39)\n",
      "tensor([44, 53, 56,  1, 58, 46, 39]) ----- tensor(58)\n",
      "tensor([44, 53, 56,  1, 58, 46, 39, 58]) ----- tensor(1)\n",
      "tensor([52]) ----- tensor(58)\n",
      "tensor([52, 58]) ----- tensor(1)\n",
      "tensor([52, 58,  1]) ----- tensor(58)\n",
      "tensor([52, 58,  1, 58]) ----- tensor(46)\n",
      "tensor([52, 58,  1, 58, 46]) ----- tensor(39)\n",
      "tensor([52, 58,  1, 58, 46, 39]) ----- tensor(58)\n",
      "tensor([52, 58,  1, 58, 46, 39, 58]) ----- tensor(1)\n",
      "tensor([52, 58,  1, 58, 46, 39, 58,  1]) ----- tensor(46)\n",
      "tensor([25]) ----- tensor(17)\n",
      "tensor([25, 17]) ----- tensor(27)\n",
      "tensor([25, 17, 27]) ----- tensor(10)\n",
      "tensor([25, 17, 27, 10]) ----- tensor(0)\n",
      "tensor([25, 17, 27, 10,  0]) ----- tensor(21)\n",
      "tensor([25, 17, 27, 10,  0, 21]) ----- tensor(1)\n",
      "tensor([25, 17, 27, 10,  0, 21,  1]) ----- tensor(54)\n",
      "tensor([25, 17, 27, 10,  0, 21,  1, 54]) ----- tensor(39)\n"
     ]
    }
   ],
   "source": [
    "# Print all the training examples in this batch.\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b][:t+1]\n",
    "        target = yb[b][t]\n",
    "        print(context, \"-----\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "224f3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RWKV(n_layer, vocab_size, n_embed, block_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "48e3523c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb.weight\n",
      "blocks.0.ln1.weight\n",
      "blocks.0.ln1.bias\n",
      "blocks.0.ln2.weight\n",
      "blocks.0.ln2.bias\n",
      "blocks.0.ln0.weight\n",
      "blocks.0.ln0.bias\n",
      "blocks.0.ffnPre.time_mix_k\n",
      "blocks.0.ffnPre.time_mix_r\n",
      "blocks.0.ffnPre.key.weight\n",
      "blocks.0.ffnPre.receptance.weight\n",
      "blocks.0.ffnPre.value.weight\n",
      "blocks.0.ffn.time_mix_k\n",
      "blocks.0.ffn.time_mix_r\n",
      "blocks.0.ffn.key.weight\n",
      "blocks.0.ffn.receptance.weight\n",
      "blocks.0.ffn.value.weight\n",
      "blocks.1.ln1.weight\n",
      "blocks.1.ln1.bias\n",
      "blocks.1.ln2.weight\n",
      "blocks.1.ln2.bias\n",
      "blocks.1.att.time_decay\n",
      "blocks.1.att.time_first\n",
      "blocks.1.att.time_mix_k\n",
      "blocks.1.att.time_mix_v\n",
      "blocks.1.att.time_mix_r\n",
      "blocks.1.att.aa\n",
      "blocks.1.att.bb\n",
      "blocks.1.att.pp\n",
      "blocks.1.att.xx\n",
      "blocks.1.att.key.weight\n",
      "blocks.1.att.receptance.weight\n",
      "blocks.1.att.value.weight\n",
      "blocks.1.att.output.weight\n",
      "blocks.1.ffn.time_mix_k\n",
      "blocks.1.ffn.time_mix_r\n",
      "blocks.1.ffn.key.weight\n",
      "blocks.1.ffn.receptance.weight\n",
      "blocks.1.ffn.value.weight\n",
      "blocks.2.ln1.weight\n",
      "blocks.2.ln1.bias\n",
      "blocks.2.ln2.weight\n",
      "blocks.2.ln2.bias\n",
      "blocks.2.att.time_decay\n",
      "blocks.2.att.time_first\n",
      "blocks.2.att.time_mix_k\n",
      "blocks.2.att.time_mix_v\n",
      "blocks.2.att.time_mix_r\n",
      "blocks.2.att.aa\n",
      "blocks.2.att.bb\n",
      "blocks.2.att.pp\n",
      "blocks.2.att.xx\n",
      "blocks.2.att.key.weight\n",
      "blocks.2.att.receptance.weight\n",
      "blocks.2.att.value.weight\n",
      "blocks.2.att.output.weight\n",
      "blocks.2.ffn.time_mix_k\n",
      "blocks.2.ffn.time_mix_r\n",
      "blocks.2.ffn.key.weight\n",
      "blocks.2.ffn.receptance.weight\n",
      "blocks.2.ffn.value.weight\n",
      "blocks.3.ln1.weight\n",
      "blocks.3.ln1.bias\n",
      "blocks.3.ln2.weight\n",
      "blocks.3.ln2.bias\n",
      "blocks.3.att.time_decay\n",
      "blocks.3.att.time_first\n",
      "blocks.3.att.time_mix_k\n",
      "blocks.3.att.time_mix_v\n",
      "blocks.3.att.time_mix_r\n",
      "blocks.3.att.aa\n",
      "blocks.3.att.bb\n",
      "blocks.3.att.pp\n",
      "blocks.3.att.xx\n",
      "blocks.3.att.key.weight\n",
      "blocks.3.att.receptance.weight\n",
      "blocks.3.att.value.weight\n",
      "blocks.3.att.output.weight\n",
      "blocks.3.ffn.time_mix_k\n",
      "blocks.3.ffn.time_mix_r\n",
      "blocks.3.ffn.key.weight\n",
      "blocks.3.ffn.receptance.weight\n",
      "blocks.3.ffn.value.weight\n",
      "ln_out.weight\n",
      "ln_out.bias\n",
      "head.weight\n"
     ]
    }
   ],
   "source": [
    "# Show all the parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "4835feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            \n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6a2bd827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.3031, val loss 4.3177\n",
      "step 100: train loss 2.7708, val loss 2.7559\n",
      "step 200: train loss 2.5842, val loss 2.5392\n",
      "step 300: train loss 2.5145, val loss 2.5212\n",
      "step 400: train loss 2.4379, val loss 2.4470\n",
      "step 500: train loss 2.3493, val loss 2.3397\n",
      "step 600: train loss 2.3284, val loss 2.3304\n",
      "step 700: train loss 2.2880, val loss 2.2946\n",
      "step 800: train loss 2.2990, val loss 2.2783\n",
      "step 900: train loss 2.2725, val loss 2.2741\n",
      "step 1000: train loss 2.2792, val loss 2.2668\n",
      "step 1100: train loss 2.2448, val loss 2.2322\n",
      "step 1200: train loss 2.2273, val loss 2.2267\n",
      "step 1300: train loss 2.1578, val loss 2.2308\n",
      "step 1400: train loss 2.1760, val loss 2.2264\n",
      "step 1500: train loss 2.1870, val loss 2.2046\n",
      "step 1600: train loss 2.1164, val loss 2.1818\n",
      "step 1700: train loss 2.1855, val loss 2.1814\n",
      "step 1800: train loss 2.1226, val loss 2.1617\n",
      "step 1900: train loss 2.1552, val loss 2.1607\n",
      "step 2000: train loss 2.0931, val loss 2.1866\n",
      "step 2100: train loss 2.1319, val loss 2.1464\n",
      "step 2200: train loss 2.1305, val loss 2.1604\n",
      "step 2300: train loss 2.1077, val loss 2.1833\n",
      "step 2400: train loss 2.0602, val loss 2.1289\n",
      "step 2500: train loss 2.0897, val loss 2.1641\n",
      "step 2600: train loss 2.0980, val loss 2.1197\n",
      "step 2700: train loss 2.1029, val loss 2.1594\n",
      "step 2800: train loss 2.0715, val loss 2.1113\n",
      "step 2900: train loss 2.0476, val loss 2.1248\n",
      "step 3000: train loss 2.0726, val loss 2.1923\n",
      "step 3100: train loss 2.0506, val loss 2.1085\n",
      "step 3200: train loss 2.0672, val loss 2.0997\n",
      "step 3300: train loss 2.0724, val loss 2.1291\n",
      "step 3400: train loss 2.0647, val loss 2.1046\n",
      "step 3500: train loss 2.0102, val loss 2.0849\n",
      "step 3600: train loss 2.0397, val loss 2.1465\n",
      "step 3700: train loss 2.0392, val loss 2.1142\n",
      "step 3800: train loss 2.0190, val loss 2.1224\n",
      "step 3900: train loss 2.0346, val loss 2.0905\n",
      "step 4000: train loss 2.0288, val loss 2.1077\n",
      "step 4100: train loss 2.0226, val loss 2.1007\n",
      "step 4200: train loss 2.0100, val loss 2.0961\n",
      "step 4300: train loss 2.0151, val loss 2.1162\n",
      "step 4400: train loss 2.0061, val loss 2.1289\n",
      "step 4500: train loss 2.0234, val loss 2.0947\n",
      "step 4600: train loss 2.0366, val loss 2.0701\n",
      "step 4700: train loss 2.0104, val loss 2.0846\n",
      "step 4800: train loss 1.9920, val loss 2.1194\n",
      "step 4900: train loss 1.9909, val loss 2.0961\n",
      "step 4999: train loss 1.9908, val loss 2.1019\n"
     ]
    }
   ],
   "source": [
    "for iter in range(max_iters):\n",
    "    \n",
    "    # Evalute the loss on train and val sets once every several iterations\n",
    "    if iter % 100 == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f'step {iter}: train loss {losses[\"train\"]:.4f}, val loss {losses[\"val\"]:.4f}')\n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "59779e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tha, wation his iuglat rewis?\n",
      "\n",
      "JULIY:\n",
      "No do come will. i' no not moun you gar; who go is shounberse?\n",
      "\n",
      "Clauton loblestgian is theing chown anyst beear the Sog,\n",
      "Come of dishallowon'd what in play I hupose to for mustroye some ewhich.\n",
      "\n",
      "Shithern, in nou upothen is, po of come otriwarest disperue,\n",
      "\n",
      "Mushould for of with sir,\n",
      "Thou my not: he goo, sha seecome whick, my don not one who heave for ohe acts would onour withsvain town, ba have which twer,\n",
      "What don I will lought ou host we one is at is reso the wordon what sone, seer more with and givey, a ted to geout this exRie i as was him say\n",
      "in't is in worddy tlies, abribeit\n",
      "if she comet.\n",
      "\n",
      "AUBE\n",
      "Not quie.\n",
      "Thee with is fighty\n",
      "So no gueibs wolp 'people care's heried shall, belagt:\n",
      "If of sen fall will at but sold mine somear:\n",
      "Now of a hath: cready, wous try's glacher;\n",
      "Bead.\n",
      "By shy to reard.\n",
      "Ord \n",
      "\n",
      "MENE:\n",
      "Go neath'teart dear\n",
      "he sage vooy Pome.\n",
      "Conet who I should welverief it your sourtue the hold chulkiname and Rome's act;\n",
      "But not this is so hiveeds w\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(context, max_new_tokes=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4a16254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text.split(' '))))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c7b041da",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s : [stoi[c] for c in s]\n",
    "decode = lambda l : \" \".join([itos[x] for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ba588b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text.split(' ')), dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "142bab88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(encode(text.split(' ')[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ae86eeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First',\n",
       " 'Citizen:\\nBefore',\n",
       " 'we',\n",
       " 'proceed',\n",
       " 'any',\n",
       " 'further,',\n",
       " 'hear',\n",
       " 'me',\n",
       " 'speak.\\n\\nAll:\\nSpeak,',\n",
       " 'speak.\\n\\nFirst']"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(' ')[: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f6928430",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "da37ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a batch of input data x and targets y\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix]) # Train on every subsequence within the input sequence\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9486870a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch('train')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "11cd27d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 64, 0.001, 4)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size, n_embed, learning_rate, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "2c4dd3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "4517287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RWKV(5, vocab_size, 256, block_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr = 3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "09f21576",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "f70f1ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 10.7898, val loss 10.8070\n",
      "step 100: train loss 8.5281, val loss 8.4840\n",
      "step 200: train loss 8.3793, val loss 8.3692\n",
      "step 300: train loss 8.3006, val loss 8.3293\n",
      "step 400: train loss 8.2460, val loss 8.3631\n",
      "step 500: train loss 8.1796, val loss 8.3537\n",
      "step 600: train loss 8.1512, val loss 8.2259\n",
      "step 700: train loss 8.1313, val loss 8.2875\n",
      "step 800: train loss 8.1293, val loss 8.3172\n",
      "step 900: train loss 8.0813, val loss 8.2449\n",
      "step 1000: train loss 8.0372, val loss 8.1785\n",
      "step 1100: train loss 7.9527, val loss 8.2137\n",
      "step 1200: train loss 7.8982, val loss 8.3145\n",
      "step 1300: train loss 7.9780, val loss 8.1859\n",
      "step 1400: train loss 7.9334, val loss 8.2834\n",
      "step 1500: train loss 7.9432, val loss 8.2515\n",
      "step 1600: train loss 7.8950, val loss 8.3395\n",
      "step 1700: train loss 7.9012, val loss 8.3019\n",
      "step 1800: train loss 7.8195, val loss 8.2493\n",
      "step 1900: train loss 7.7865, val loss 8.2996\n",
      "step 2000: train loss 7.8558, val loss 8.3906\n",
      "step 2100: train loss 7.7159, val loss 8.2603\n",
      "step 2200: train loss 7.6858, val loss 8.2898\n",
      "step 2300: train loss 7.6355, val loss 8.2670\n",
      "step 2400: train loss 7.6265, val loss 8.2919\n",
      "step 2500: train loss 7.7104, val loss 8.2006\n",
      "step 2600: train loss 7.6135, val loss 8.2314\n",
      "step 2700: train loss 7.6380, val loss 8.3362\n",
      "step 2800: train loss 7.5646, val loss 8.1790\n",
      "step 2900: train loss 7.5790, val loss 8.3597\n",
      "step 3000: train loss 7.5664, val loss 8.3576\n",
      "step 3100: train loss 7.4552, val loss 8.2343\n",
      "step 3200: train loss 7.5244, val loss 8.2792\n",
      "step 3300: train loss 7.4245, val loss 8.3046\n",
      "step 3400: train loss 7.4516, val loss 8.3050\n",
      "step 3500: train loss 7.3647, val loss 8.2795\n",
      "step 3600: train loss 7.3870, val loss 8.3555\n",
      "step 3700: train loss 7.3606, val loss 8.3916\n",
      "step 3800: train loss 7.3763, val loss 8.4874\n",
      "step 3900: train loss 7.3158, val loss 8.3883\n",
      "step 4000: train loss 7.2934, val loss 8.3797\n",
      "step 4100: train loss 7.3558, val loss 8.3887\n",
      "step 4200: train loss 7.2610, val loss 8.3387\n",
      "step 4300: train loss 7.2285, val loss 8.3860\n",
      "step 4400: train loss 7.2299, val loss 8.3887\n",
      "step 4500: train loss 7.1703, val loss 8.3223\n",
      "step 4600: train loss 7.1972, val loss 8.4661\n",
      "step 4700: train loss 7.1937, val loss 8.4721\n",
      "step 4800: train loss 7.1768, val loss 8.4763\n",
      "step 4900: train loss 7.1770, val loss 8.4631\n",
      "step 4999: train loss 7.1390, val loss 8.4532\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr=3e-4)\n",
    "batch_size = 4\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % 100 == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "49034014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O Romeo, Romeo, of his mother,\n",
      "He dried thence.\n",
      "\n",
      "Second sickness the king,\n",
      "I'll of your friends':\n",
      "God and misusest.\n",
      "\n",
      "KING government,\n",
      "Shall, to Vienna.\n",
      "\n",
      "POMPEY:\n",
      "Does law disdains fair Lodowick?\n",
      "\n",
      "LUCIO:\n",
      "My proclaim'd: doth not answer, will not hap? me to meddle with within! maw, good:\n",
      "the fall, the crown.\n",
      "\n",
      "YORK:\n",
      "'Twas then divine men?\n",
      "If as humane\n",
      "And one: not to him: VINCENTIO:\n",
      "There's partake must be the matter:--Nurse, No, loves OF get entreat no baited\n",
      "With but same it Paulina,\n",
      "Make a take\n",
      "From OVERDONE:\n",
      "What's well; aid: begot the earth to offends suspicion! upon this crown and both do; grows to her I side;\n",
      "The I can Down, learn to take promise keep to I:\n",
      "No, heart\n",
      "To OF last,\n",
      "Definitively and condition,\n"
     ]
    }
   ],
   "source": [
    "context = torch.tensor([encode(\"O Romeo, Romeo,\".split(' '))], dtype = torch.long)\n",
    "print(decode(model.generate(context, max_new_tokes=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "137b5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"rwkw_shakespeare_words_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e833f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
