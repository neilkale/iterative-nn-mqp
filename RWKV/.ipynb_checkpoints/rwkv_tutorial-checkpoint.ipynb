{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec92a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdae1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelMix(nn.Module):\n",
    "    def __init__(self, layer_id, n_layer, n_embed):\n",
    "        super().__init__()\n",
    "        self.layer_id = layer_id\n",
    "        \n",
    "        self.time_shift = nn.ZeroPad2d((0, 0, 1, -1))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ratio_1_to_almost0 = 1.0 - layer_id/n_layer\n",
    "            x = torch.ones(1,1, n_embed)\n",
    "            for i in range(n_embed):\n",
    "                x[0, 0, i] = i/n_embed\n",
    "            \n",
    "            self.time_mix_k = nn.Parameter(torch.pow(x, ratio_1_to_almost0))\n",
    "            self.time_mix_r = nn.Parameter(torch.pow(x, ratio_1_to_almost0))\n",
    "        \n",
    "        hidden_size = 4*n_embed\n",
    "        self.key = nn.Linear(n_embed, hidden_size, bias=False)\n",
    "        self.receptance = nn.Linear(n_embed, n_embed, bias=False)\n",
    "        \n",
    "        self.value = nn.Linear(hidden_size, n_embed, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xx = self.time_shift(x)\n",
    "        xk = x * self.time_mix_k + (1-self.time_mix_k) * xx\n",
    "\n",
    "        xr = x * self.time_mix_r + (1-self.time_mix_r) * xx\n",
    "        \n",
    "        k = self.key(xk)\n",
    "        k = torch.square(torch.relu(k))\n",
    "        \n",
    "        kv = self.value(k)\n",
    "        \n",
    "        \n",
    "        \n",
    "        rkv = torch.sigmoid(self.receptance(xr)) * kv\n",
    "        \n",
    "        return rkv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2201e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeMix(nn.Module):\n",
    "    def __init__(self, layer_id, n_layer, n_embed):\n",
    "        super().__init__()\n",
    "        self.layer_id = layer_id\n",
    "        \n",
    "        attn_sz = n_embed\n",
    "        with torch.no_grad():\n",
    "            ratio_1_to_almost0 = 1.0 - layer_id/n_layer\n",
    "            ratio_0_to_1 = layer_id / (n_layer - 1)\n",
    "            \n",
    "            decay_speed = torch.ones(attn_sz)\n",
    "            for h in range(attn_sz):\n",
    "                decay_speed[h] = -5 + 8 * (h / (attn_sz-1)) ** (0.7 + 1.3 * ratio_0_to_1)\n",
    "                \n",
    "            self.time_decay = nn.Parameter(decay_speed)\n",
    "            \n",
    "            zigzag = (torch.tensor([(i+1)%3 - 1 for i in range(attn_sz)]) * 0.5)\n",
    "            self.time_first = nn.Parameter(torch.ones(attn_sz) * math.log(0.3) + zigzag)\n",
    "                \n",
    "            \n",
    "            x = torch.ones(1,1, n_embed)\n",
    "            for i in range(n_embed):\n",
    "                x[0, 0, i] = i/n_embed\n",
    "            \n",
    "            self.time_mix_k = nn.Parameter(torch.pow(x, ratio_1_to_almost0))\n",
    "            self.time_mix_v = nn.Parameter(torch.pow(x, ratio_1_to_almost0) +0.3 * ratio_0_to_1)\n",
    "            self.time_mix_r = nn.Parameter(torch.pow(x, 0.5 * ratio_1_to_almost0))\n",
    "        \n",
    "            self.aa = nn.Parameter(torch.ones(1,1,attn_sz))\n",
    "            self.bb = nn.Parameter(torch.ones(1,1,attn_sz))\n",
    "            pp = torch.ones(1,1,attn_sz)\n",
    "            pp = pp * -1e30\n",
    "            self.pp = nn.Parameter(pp)\n",
    "            self.xx = nn.Parameter(torch.ones(1,1,attn_sz))\n",
    "        \n",
    "        hidden_size = attn_sz\n",
    "        self.key = nn.Linear(n_embed, attn_sz, bias=False)\n",
    "        self.receptance = nn.Linear(n_embed, attn_sz, bias=False)\n",
    "        \n",
    "        self.value = nn.Linear(hidden_size, attn_sz, bias=False)\n",
    "        self.output = nn.Linear(attn_sz, n_embed, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        xx = self.xx\n",
    "\n",
    "       \n",
    "        xk = x * self.time_mix_k + (1-self.time_mix_k) * xx\n",
    "        xv = x * self.time_mix_v + (1-self.time_mix_v) * xx\n",
    "        xr = x * self.time_mix_r + (1-self.time_mix_r) * xx\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        k = self.key(xk)\n",
    "        \n",
    "        \n",
    "        v = self.value(xv)\n",
    "        r= self.receptance(xr)\n",
    "        \n",
    "            \n",
    "        r =torch.sigmoid(r)\n",
    "        \n",
    "        # Calculate the difference in size along the non-singleton dimension\n",
    "        diff = k.shape[1] - self.aa.shape[1]\n",
    "    \n",
    "        \n",
    "        b,t,c = x.shape\n",
    "        aa = torch.nn.functional.pad(self.aa, (0, 0, 0, diff, 0, 0))\n",
    "        bb = torch.nn.functional.pad(self.bb, (0, 0, 0, diff, 0, 0))\n",
    "        pp = torch.nn.functional.pad(self.pp, (0, 0, 0, diff, 0, 0))\n",
    "             \n",
    "            \n",
    "        ww = self.time_first + k\n",
    "    \n",
    "        \n",
    "        qq = torch.maximum(pp, ww )\n",
    "        e1 = torch.exp(pp - qq)\n",
    "        e2 = torch.exp(ww - qq)\n",
    "        \n",
    "        a = e1 * aa + e2 * v\n",
    "        \n",
    "        b = e1 * bb + e2\n",
    "        wkv = a / b\n",
    "        \n",
    "        ww = pp + self.time_decay\n",
    "        qq = torch.maximum(ww, k)\n",
    "        e1 = torch.exp(ww - qq)\n",
    "        e2 = torch.exp(k - qq)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            xx = nn.Parameter(x)\n",
    "            self.aa = nn.Parameter(e1 * aa + e2 * v)\n",
    "            self.bb = nn.Parameter(e1 * bb + e2)\n",
    "            self.pp = nn.Parameter(qq)\n",
    "            \n",
    "        \n",
    "        return self.output(r * wkv)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734c6ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, layer_id, n_layer, n_embd):\n",
    "        super().__init__()\n",
    "        self.layer_id = layer_id\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "        if self.layer_id == 0:\n",
    "            self.ln0 = nn.LayerNorm(n_embd)\n",
    "\n",
    "        if self.layer_id == 0 :\n",
    "            self.ffnPre = ChannelMix(0, n_layer, n_embd)\n",
    "        else:\n",
    "            self.att = TimeMix(layer_id, n_layer, n_embd)\n",
    "\n",
    "        self.ffn = ChannelMix(layer_id, n_layer, n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.layer_id == 0:\n",
    "            x = self.ln0(x)        \n",
    "        if self.layer_id == 0 :\n",
    "            x = x + self.ffnPre(self.ln1(x))  # better in some cases\n",
    "        else:\n",
    "            x = x + self.att(self.ln1(x))\n",
    "        x = x + self.ffn(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa4d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RWKV(nn.Module):\n",
    "    def __init__(self, n_layer, vocab_size,  n_embd, ctx_len):\n",
    "        super().__init__()\n",
    "        self.step = 0\n",
    "        self.ctx_len = ctx_len\n",
    "        self.emb = nn.Embedding(vocab_size, n_embd)\n",
    "\n",
    "        self.blocks = nn.Sequential(*[Block(i, n_layer, n_embd)\n",
    "                                    for i in range(n_layer)])\n",
    "\n",
    "        self.ln_out = nn.LayerNorm(n_embd)\n",
    "        self.head = nn.Linear(n_embd, vocab_size, bias=False)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "            idx = idx.to(self.emb.weight.device)\n",
    "\n",
    "            self.step += 1\n",
    "            \n",
    "            B, T = idx.size()\n",
    "            assert T <= self.ctx_len, \"Cannot forward, because len(input) > model ctx_len.\"\n",
    "\n",
    "            x = self.emb(idx)\n",
    "            x = self.blocks(x)\n",
    "            x = self.ln_out(x)\n",
    "\n",
    "            x = self.head(x)\n",
    "            \n",
    "\n",
    "            loss = None\n",
    "            if targets is not None:\n",
    "                loss = F.cross_entropy(x.view(-1, x.size(-1)), targets.to(x.device).view(-1))\n",
    "            x = torch.mean(x, dim=0, keepdim=True)\n",
    "            return x, loss\n",
    "        \n",
    "    def generate(self, idx, max_new_tokes):\n",
    "        for _ in range(max_new_tokes):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0a587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e18c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c95d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05d2bebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b464109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff2afa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0938e47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(''.join(chars))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e9de93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = {i:ch for i,ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60bf71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {i:ch for i,ch in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c56a3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[x] for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b1a344c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 47, 1, 58, 46, 43, 56, 43]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5d70559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi there'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([46, 47, 1, 58, 46, 43, 56, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2516b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d23be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f75b39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1115394]), torch.Tensor)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d091094",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26ca3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34787a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45fefb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78c8a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[1:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca9d4cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18, 47, 56, 57, 58,  1, 15, 47]),\n",
       " tensor([47, 56, 57, 58,  1, 15, 47, 58]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1531c3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctx  tensor([18]) target tensor(47)\n",
      "ctx  tensor([18, 47]) target tensor(56)\n",
      "ctx  tensor([18, 47, 56]) target tensor(57)\n",
      "ctx  tensor([18, 47, 56, 57]) target tensor(58)\n",
      "ctx  tensor([18, 47, 56, 57, 58]) target tensor(1)\n",
      "ctx  tensor([18, 47, 56, 57, 58,  1]) target tensor(15)\n",
      "ctx  tensor([18, 47, 56, 57, 58,  1, 15]) target tensor(47)\n",
      "ctx  tensor([18, 47, 56, 57, 58,  1, 15, 47]) target tensor(58)\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(\"ctx \", context, \"target\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f10f220f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2207efc84b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a32aefce",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84178d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6866578",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d5a0228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "451bb3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13c1cc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
       "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
       "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
       "        [25, 17, 27, 10,  0, 21,  1, 54]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7c40762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24]) ----- tensor(43)\n",
      "tensor([24, 43]) ----- tensor(58)\n",
      "tensor([24, 43, 58]) ----- tensor(5)\n",
      "tensor([24, 43, 58,  5]) ----- tensor(57)\n",
      "tensor([24, 43, 58,  5, 57]) ----- tensor(1)\n",
      "tensor([24, 43, 58,  5, 57,  1]) ----- tensor(46)\n",
      "tensor([24, 43, 58,  5, 57,  1, 46]) ----- tensor(43)\n",
      "tensor([24, 43, 58,  5, 57,  1, 46, 43]) ----- tensor(39)\n",
      "tensor([44]) ----- tensor(53)\n",
      "tensor([44, 53]) ----- tensor(56)\n",
      "tensor([44, 53, 56]) ----- tensor(1)\n",
      "tensor([44, 53, 56,  1]) ----- tensor(58)\n",
      "tensor([44, 53, 56,  1, 58]) ----- tensor(46)\n",
      "tensor([44, 53, 56,  1, 58, 46]) ----- tensor(39)\n",
      "tensor([44, 53, 56,  1, 58, 46, 39]) ----- tensor(58)\n",
      "tensor([44, 53, 56,  1, 58, 46, 39, 58]) ----- tensor(1)\n",
      "tensor([52]) ----- tensor(58)\n",
      "tensor([52, 58]) ----- tensor(1)\n",
      "tensor([52, 58,  1]) ----- tensor(58)\n",
      "tensor([52, 58,  1, 58]) ----- tensor(46)\n",
      "tensor([52, 58,  1, 58, 46]) ----- tensor(39)\n",
      "tensor([52, 58,  1, 58, 46, 39]) ----- tensor(58)\n",
      "tensor([52, 58,  1, 58, 46, 39, 58]) ----- tensor(1)\n",
      "tensor([52, 58,  1, 58, 46, 39, 58,  1]) ----- tensor(46)\n",
      "tensor([25]) ----- tensor(17)\n",
      "tensor([25, 17]) ----- tensor(27)\n",
      "tensor([25, 17, 27]) ----- tensor(10)\n",
      "tensor([25, 17, 27, 10]) ----- tensor(0)\n",
      "tensor([25, 17, 27, 10,  0]) ----- tensor(21)\n",
      "tensor([25, 17, 27, 10,  0, 21]) ----- tensor(1)\n",
      "tensor([25, 17, 27, 10,  0, 21,  1]) ----- tensor(54)\n",
      "tensor([25, 17, 27, 10,  0, 21,  1, 54]) ----- tensor(39)\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b][:t+1]\n",
    "        target = yb[b][t]\n",
    "        print(context, \"-----\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2a31dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RWKV( n_layer, vocab_size, n_embd, block_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d480c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            \n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04dce38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.2970, val loss 4.3110\n",
      "step 100: train loss 2.7697, val loss 2.7565\n",
      "step 200: train loss 2.5853, val loss 2.5406\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m xb, yb \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# evaluate the loss\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m, in \u001b[0;36mRWKV.forward\u001b[1;34m(self, idx, targets)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m T \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx_len, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot forward, because len(input) > model ctx_len.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb(idx)\n\u001b[1;32m---> 23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_out(x)\n\u001b[0;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[4], line 26\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39matt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(x))\n\u001b[1;32m---> 26\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[2], line 36\u001b[0m, in \u001b[0;36mChannelMix.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m k \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msquare(torch\u001b[38;5;241m.\u001b[39mrelu(k))\n\u001b[0;32m     32\u001b[0m kv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(k)\n\u001b[1;32m---> 36\u001b[0m rkv \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceptance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m kv\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rkv\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % 100 == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(context, max_new_tokes=1000)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd14f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text.split(' '))))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b794a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf33411",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \" \".join([itos[x] for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0b3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text.split(' ')), dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b97e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(encode(text.split(' ')[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb2236",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.split(' ')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_batch('train')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size, n_embd, learning_rate, batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce12375",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521803fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RWKV( 5, vocab_size, 256, block_size)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            \n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79119cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr=3e-4)\n",
    "batch_size = 4\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % 100 == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.tensor([encode(\"HENRY all divided? night\".split(' '))], dtype = torch.long)\n",
    "print(decode(model.generate(context, max_new_tokes=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc46951",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = torch.tensor([encode(\"George\".split(' '))], dtype = torch.long)\n",
    "print(decode(model.generate(context, max_new_tokes=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d6889c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
